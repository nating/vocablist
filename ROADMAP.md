# ROADMAP â€“ vocablist

> This file is the single source of truth for Codex-driven development. After each merged PR, Codex must mark completed tasks with âœ…, then open the next unchecked task as a new issue using the **Feature / Task** template. When all tasks in a milestone are done, tick the milestone header.
> Bear in mind that this file too was AI generated. You have are pretty free to come up with your own next steps if you think you know better. Or if you think that you know better (free) tools for the job (and can back up your decisions with recent sources), then you are very welcome to do things in a different way.

## M0 â€“ Repo Foundation & Governance

- [x] T0â€‘01 Initialize Git repository `vocablist`, add MIT License, README scaffold
- [x] T0â€‘02 Commit `AGENTS.md` and `ROADMAP.md` seeds
- [x] T0â€‘03 Add `.editorconfig`, `.nvmrc`, and root `pnpm-workspace.yaml`
- [x] T0â€‘04 Set up branch protection rules; commit `CODEOWNERS` (maintainer) and default labels
- [x] T0â€‘05 Add GitHub Issue templates (`ðŸ’¡ Feature / Task`, `ðŸ›  Manual / Ops`, PR template)
- [ ] T0â€‘06 Enable Vercel Remote Cache tokens & add `TURBO_TOKEN`, `TURBO_TEAM` as **TODO secrets**
- [x] T0â€‘07 Install Husky + lintâ€‘staged preâ€‘commit hooks
- [ ] T0â€‘08 Create GitHub Project board `Backlog` columns: Todo / Inâ€‘Progress / Review / Done

## M1 â€“ Monorepo Skeleton & CI

- [ ] T1â€‘01 Run `pnpm dlx create-turbo@latest` to scaffold monorepo (`apps/`, `packages/`)
- [ ] T1â€‘02 Add base TypeScript `tsconfig` and enable `strict`
- [ ] T1â€‘03 Install ESLint with `@typescript-eslint`, `eslint-config-turbo`; configure Prettier + Tailwind plugin
- [ ] T1â€‘04 Add Vitest & coverage threshold 95%
- [ ] T1â€‘05 GitHub Actions workflow `ci.yml`: lint â†’ test â†’ build using Turborepo cache
- [ ] T1â€‘06 Workflow `deploy-preview.yml`: on PR push preview to Vercel (`--prebuilt`)
- [ ] T1â€‘07 Workflow `deploy-prod.yml`: on merge into `main` promote to production

## M2 â€“ Auth & Database

- [ ] T2â€‘01 Provision Neon Free Postgres project (manual) and set `DATABASE_URL` secret
- [ ] T2â€‘02 Package `packages/db`: Drizzle schema & migrations for `user`
- [ ] T2â€‘03 Integrate BetterAuth in `apps/api` (Express or Next route handlers)
- [ ] T2â€‘04 Add signâ€‘up / signâ€‘in pages in Next.js 15 App Router
- [ ] T2â€‘05 Write integration tests for auth flow with Supertest & embedded Postgres

## M3 â€“ Media Core Schema

- [ ] T3â€‘01 Extend Drizzle schema: `media`, `episode`, `subtitle_line`, `token`, `known_token`
- [ ] T3â€‘02 Seed script generating sample media and user for dev
- [ ] T3â€‘03 Add GraphQL or tRPC endpoint `/media/:id` returning basic media meta

## M4 â€“ Upload & Storage

- [ ] T4â€‘01 Create Supabase project (manual) and add `SUPABASE_URL`, `SUPABASE_KEY` secrets
- [ ] T4â€‘02 Next.js upload page with dragâ€‘andâ€‘drop `.srt` (Zod validation)
- [ ] T4â€‘03 Store raw `.srt` in Supabase Storage bucket `subtitles/`
- [ ] T4â€‘04 Enqueue BullMQ `ingest` job with file URL, mediaId

## M5 â€“ Queue & Worker

- [ ] T5â€‘01 Provision Upstash Redis free DB (manual) and add `REDIS_URL` secret
- [ ] T5â€‘02 Set up `apps/worker` container; subscribe to `ingest` queue
- [ ] T5â€‘03 Install spaCy with English model in worker Docker image
- [ ] T5â€‘04 Worker parses SRT, tokenizes, lemmatizes; bulk inserts tokens via Drizzle
- [ ] T5â€‘05 Unit tests for tokenizer logic (spaCy mocks) & integration test against Neon using pgâ€‘embed

## M6 â€“ Frequency & Chronology API

- [ ] T6â€‘01 SQL materialized view `media_token_frequency` (token, count, pct)
- [ ] T6â€‘02 Endpoint `/media/:id/tokens?order=frequency|chrono` with pagination
- [ ] T6â€‘03 Add TanStack Query hooks in frontend to fetch token lists

## M7 â€“ Frontend Tables & UI

- [ ] T7â€‘01 Tailwind 4 powered table components with sortable headers & virtualised rows
- [ ] T7â€‘02 Media detail page shows frequency and chronological tables
- [ ] T7â€‘03 Add global layout, navigation bar, dark mode toggle (shadcn/ui)
- [ ] T7â€‘04 Lighthouse CI run to keep perf > 90

## M8 â€“ Known Words & Coverage

- [ ] T8â€‘01 User settings UI: textarea paste list of known words
- [ ] T8â€‘02 Backend endpoint to upsert `known_token` list (Zod validated)
- [ ] T8â€‘03 Coverage algorithm: percentage of token occurrences covered
- [ ] T8â€‘04 Badge component on Media page displaying coverage
- [ ] T8â€‘05 E2E tests with Playwright: upload SRT, mark known words, expect â‰¥ badge

## M9 â€“ Deployment Secrets & Envs

- [ ] T9â€‘01 Document all required env vars in `docs/ENVIRONMENT.md`
- [ ] T9â€‘02 GitHub Actions step to `echo $LATEST_ENV` into Vercel for previews
- [ ] T9â€‘03 Manual ops issue: configure Cloudflare Workers project (API edge) and add tokens

## M10 â€“ OpenSubtitles Crawler

- [ ] T10â€‘01 Create service `apps/crawler` with cron schedule (GitHub Actions or Workers Cron)
- [ ] T10â€‘02 Implement licensed download flow, respect rate limits
- [ ] T10â€‘03 Parse metadata, create media records, enqueue ingest jobs
- [ ] T10â€‘04 Admin UI page listing crawl backlog & failures

## M11 â€“ Multiâ€‘language Support

- [ ] T11â€‘01 Auto languageâ€‘detect SRT via Compact Language Detector
- [ ] T11â€‘02 Add spaCy pipelines for JP, ES, DE using appropriate models
- [ ] T11â€‘03 Token table gains `language` column; DB index adjustments
- [ ] T11â€‘04 UI language switch and flag display

## M12 â€“ Export & Study Assets

- [ ] T12â€‘01 Implement CSV export endpoint with proper mime headers
- [ ] T12â€‘02 Integrate `genanki-js` to create deck (.apkg) per media
- [ ] T12â€‘03 Queue job `export_anki`; upload result to Supabase Storage and provide signed URL
- [ ] T12â€‘04 Add "Download CSV" and "Download Anki" buttons in UI

## M13 â€“ MCP Server Integration

- [ ] T13â€‘01 Implement Model Context Protocol client; schedule sync of user vocab
- [ ] T13â€‘02 Allow users to link MCP account from settings page
- [ ] T13â€‘03 Backfill `known_token` via MCP tokens

## M14 â€“ Series / Season Hierarchy

- [ ] T14â€‘01 DB migration: `series`, `season` tables; link episodes
- [ ] T14â€‘02 API returns aggregated coverage across season / series
- [ ] T14â€‘03 UI breadcrumb & selector season/episode

## M15 â€“ Word Recommendation Engine

- [ ] T15â€‘01 Simple TFâ€‘IDF based ranking of top unknown tokens per user & media
- [ ] T15â€‘02 Endpoint `/media/:id/recommendations` returns list with definitions (lookup dictionary API)
- [ ] T15â€‘03 Side panel in UI showing top 20 words to learn next

## M16 â€“ Observability & Cost Dashboards

- [ ] T16â€‘01 Add Pino logging + stdout JSON; pipe to Logtail free tier
- [ ] T16â€‘02 Add Prometheus compatible metrics endpoint; scrape with Grafana Cloud free
- [ ] T16â€‘03 Weekly GitHub Action to summarise Upstash/Neon usage and open `ðŸ›  Manual` issue if near limits

## M17 â€“ Paid Tier Prep

- [ ] T17â€‘01 Terms of Service & Privacy Policy pages

## M18 â€“ Polish & Accessibility

- [ ] T18â€‘01 a11y audit, fix contrast and keyboard nav issues
- [ ] T18â€‘02 Internationalized UI strings via `next-intl`
- [ ] T18â€‘03 Endâ€‘toâ€‘end smoke tests for critical flows on CI
- [ ] T18â€‘04 Documentation site using Next.js static export (`/docs`)
